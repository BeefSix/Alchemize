# app/db/crud.py
from sqlalchemy.orm import Session
from app.db import models
from app.services.auth import get_password_hash # Assuming get_password_hash is from services.auth
from datetime import datetime, date, timedelta
import json # For serializing/deserializing JSON columns

# --- User CRUD ---
def get_user_by_id(db: Session, user_id: int):
    return db.query(models.User).filter(models.User.id == user_id).first()

def get_user_by_email(db: Session, email: str):
    return db.query(models.User).filter(models.User.email == email).first()

def create_user(db: Session, email: str, password: str, full_name: str | None = None):
    hashed_password = get_password_hash(password)
    # The `models.User` in the new structure uses `id` as Integer and `user_id` is not present.
    # Assuming `id` is auto-generated by DB or passed explicitly
    # For a new user, `id` might not be known yet, or you might generate a UUID if it's string.
    # Based on your app.py, your old database.create_user took (user_id, email, hashed_password)
    # where user_id was a UUID string.
    # Let's adjust this to use the `id` column as generated by SQLAlchemy or explicitly set if it's UUID.
    # If `models.User.id` is INT and auto-incrementing, then remove `user_id` from constructor.
    # If `models.User.id` is TEXT and UUID, then set it here.
    
    # Assuming `models.User.id` is an auto-incrementing integer or we don't set it manually here.
    # If your models.User.id is a String (UUID), uncomment/modify below:
    # new_user_id = str(uuid.uuid4()) # if models.User.id is string
    # db_user = models.User(id=new_user_id, email=email, hashed_password=hashed_password, full_name=full_name)

    db_user = models.User(email=email, hashed_password=hashed_password, full_name=full_name) # Assuming ID is auto-gen or nullable
    db.add(db_user)
    db.commit()
    db.refresh(db_user)
    return db_user

# --- Job CRUD ---
# Adjusted create_job to reflect new models.Job structure (id as String, user_id as Integer ForeignKey)
def create_job(db: Session, job_id: str, user_id: int, job_type: str):
    # Ensure user_id matches the Integer type in models.Job
    db_job = models.Job(id=job_id, user_id=user_id, status="PENDING", job_type=job_type)
    db.add(db_job)
    db.commit()
    db.refresh(db_job)
    return db_job

# Adjusted get_job to reflect new models.Job structure
def get_job(db: Session, job_id: str):
    job = db.query(models.Job).filter(models.Job.id == job_id).first()
    # When retrieving, we need to load JSON strings back into Python objects
    if job:
        # Pydantic models in endpoints will handle the final serialization to JSON
        # Here, we ensure the ORM model's text fields are Python objects
        if job.progress_details and isinstance(job.progress_details, str):
            try: job.progress_details = json.loads(job.progress_details)
            except json.JSONDecodeError: job.progress_details = None
        if job.results and isinstance(job.results, str):
            try: job.results = json.loads(job.results)
            except json.JSONDecodeError: job.results = None
        
        # The 'thumbnail_urls' and 'video_clip_urls' are part of 'results' in the new schema
        # but were separate columns in your old db. Here we keep it consistent with the new model
        # and your request to fix the main error. The app.py will then access them via job.results.
        
    return job

# This is the unified function for updating jobs, used by Celery tasks
def update_job_full_status(
    db: Session, 
    job_id: str, 
    status: str | None = None, # Make status optional, only update if provided
    progress_details: dict | None = None, 
    results: dict | None = None, 
    error_message: str | None = None
):
    job = db.query(models.Job).filter(models.Job.id == job_id).first()
    if job:
        if status is not None:
            job.status = status
        
        if progress_details is not None:
            # Ensure percentage is always set for UI display if progress details are provided
            step = progress_details.get("step", 0)
            total_steps = progress_details.get("total_steps", 1)
            progress_details["percentage"] = int((step / total_steps) * 100) if total_steps > 0 else 0
            job.progress_details = json.dumps(progress_details) # Store as JSON string
        
        if results is not None:
            job.results = json.dumps(results) # Store as JSON string
        
        if error_message is not None:
            job.error_message = error_message
        
        db.commit()
        db.refresh(job)
    return job

# --- Brand Profile CRUD ---
# Assumes `brand_profiles` table exists and matches models.BrandProfile (you'll need to add this ORM model)
# If models.BrandProfile is not defined, you'll need to create it.
# E.g. in models.py:
# class BrandProfile(Base):
#     __tablename__ = "brand_profiles"
#     profile_id = Column(Integer, primary_key=True, autoincrement=True)
#     user_id = Column(Integer, ForeignKey("users.id")) # Or String if user.id is string
#     brand_voice = Column(Text, nullable=True)
#     brand_cta = Column(Text, nullable=True)

def get_brand_profile(db: Session, user_id: int):
    profile = db.query(models.BrandProfile).filter(models.BrandProfile.user_id == user_id).first()
    if profile:
        return {"brand_voice": profile.brand_voice, "brand_cta": profile.brand_cta}
    return {}

def update_brand_profile(db: Session, user_id: int, brand_voice: str | None = None, brand_cta: str | None = None):
    # Ensure user exists for brand profile, or create a stub if necessary (depends on flow)
    # For now, assumes user already exists or caller handles.
    
    profile = db.query(models.BrandProfile).filter(models.BrandProfile.user_id == user_id).first()
    if profile:
        if brand_voice is not None:
            profile.brand_voice = brand_voice
        if brand_cta is not None:
            profile.brand_cta = brand_cta
    else:
        profile = models.BrandProfile(user_id=user_id, brand_voice=brand_voice, brand_cta=brand_cta)
        db.add(profile)
    db.commit()
    db.refresh(profile)
    return profile

# --- Usage Log CRUD ---
# Assumes `usage_logs` table exists and matches models.UsageLog (you'll need to add this ORM model)
# E.g. in models.py:
# class UsageLog(Base):
#     __tablename__ = "usage_logs"
#     log_id = Column(Integer, primary_key=True, autoincrement=True)
#     user_id = Column(Integer, ForeignKey("users.id")) # Or String if user.id is string
#     timestamp = Column(DateTime(timezone=True), server_default=func.now())
#     model = Column(String)
#     operation = Column(String)
#     cost = Column(Float, nullable=False)

def track_usage(db: Session, user_id: int, model: str, operation: str, cost: float):
    log = models.UsageLog(user_id=user_id, model=model, operation=operation, cost=cost)
    db.add(log)
    db.commit()
    db.refresh(log)
    return log

def get_usage_summary(db: Session, user_id: int | None = None):
    today = datetime.utcnow().date()
    
    total_cost_query = db.query(models.UsageLog.cost).filter(models.UsageLog.user_id == user_id) if user_id else db.query(models.UsageLog.cost)
    total_cost = sum(r[0] for r in total_cost_query.all()) if total_cost_query.count() > 0 else 0

    daily_cost_query = db.query(models.UsageLog.cost).filter(models.UsageLog.timestamp >= today)
    if user_id:
        daily_cost_query = daily_cost_query.filter(models.UsageLog.user_id == user_id)
    daily_cost = sum(r[0] for r in daily_cost_query.all()) if daily_cost_query.count() > 0 else 0
    
    return {"total_cost": total_cost, "daily_cost": daily_cost}

def get_user_videos_today(db: Session, user_id: int):
    today_start = datetime.combine(date.today(), datetime.min.time()) # Midnight today UTC
    count = db.query(models.UsageLog).filter(
        models.UsageLog.user_id == user_id,
        models.UsageLog.operation.in_(['video', 'videoclip']), # Check both for consistency
        models.UsageLog.timestamp >= today_start
    ).count()
    return count

# --- Cache CRUD (for API responses and Transcripts) ---
# Assumes `api_cache` and `transcripts` tables/models exist.
# For transcripts, the 'data' is now directly JSON in the DB model `transcript_json`.

# You will need to define `models.APICache` and `models.TranscriptCache` in `models.py`
# Example:
# class APICache(Base):
#     __tablename__ = "api_cache"
#     cache_id = Column(Integer, primary_key=True, autoincrement=True)
#     request_hash = Column(String, unique=True, nullable=False)
#     response_text = Column(Text, nullable=False)
#     created_at = Column(DateTime(timezone=True), server_default=func.now())

# class TranscriptCache(Base):
#     __tablename__ = "transcripts" # Make sure this matches your old table name
#     source_url = Column(String, primary_key=True)
#     transcript_json = Column(Text, nullable=False) # JSON string
#     created_at = Column(DateTime(timezone=True), server_default=func.now())


def get_cached_response(db: Session, request_hash: str):
    cache_entry = db.query(models.APICache).filter(models.APICache.request_hash == request_hash).first()
    if cache_entry:
        return cache_entry.response_text # This is stored as a string
    return None

def set_cached_response(db: Session, request_hash: str, response_text: str):
    # Use insert or update on conflict if request_hash is unique
    existing_entry = db.query(models.APICache).filter(models.APICache.request_hash == request_hash).first()
    if existing_entry:
        existing_entry.response_text = response_text
        existing_entry.created_at = datetime.utcnow() # Update timestamp
    else:
        new_entry = models.APICache(request_hash=request_hash, response_text=response_text, created_at=datetime.utcnow())
        db.add(new_entry)
    db.commit()

def get_cached_transcript(db: Session, source_url: str):
    transcript_entry = db.query(models.TranscriptCache).filter(models.TranscriptCache.source_url == source_url).first()
    if transcript_entry and transcript_entry.transcript_json:
        try:
            return json.loads(transcript_entry.transcript_json) # Load from JSON string
        except json.JSONDecodeError:
            print(f"Warning: Cached transcript for {source_url} is not valid JSON.")
            return None
    return None

def set_cached_transcript(db: Session, source_url: str, transcript_data: dict):
    transcript_json = json.dumps(transcript_data) # Store as JSON string
    existing_entry = db.query(models.TranscriptCache).filter(models.TranscriptCache.source_url == source_url).first()
    if existing_entry:
        existing_entry.transcript_json = transcript_json
        existing_entry.created_at = datetime.utcnow()
    else:
        new_entry = models.TranscriptCache(source_url=source_url, transcript_json=transcript_json, created_at=datetime.utcnow())
        db.add(new_entry)
    db.commit()